{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.discretisers import EqualWidthDiscretiser, EqualFrequencyDiscretiser\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Print all columns to jupyter notebook\n",
    "\n",
    "DATA_PATH = r'../data/credit.csv'\n",
    "DATA_OUTPUT = r'../data/credit_output_binned.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "numeric_cols = [\n",
    "    'checking_amt',\n",
    "    'duration',\n",
    "    'credit_amount',\n",
    "    'savings',\n",
    "    'installment_commitment', # Don't think this is categorical\n",
    "    'residence_since',\n",
    "    'age',\n",
    "    'existing_credits',\n",
    "    'num_dependents'\n",
    "] \n",
    "categorical_cols = list(set(df.columns) - set(numeric_cols))\n",
    "\n",
    "LOC_REPLACE_THRESHOLD = 8\n",
    "BIN_VALUES = True\n",
    "\n",
    "\"\"\"\n",
    "Remove bad data - Quick removal of rows that contain garbage data\n",
    "\"\"\"\n",
    "# Remove where rows are almost entirely empty\n",
    "df = df[df['location'] != '?'] # removes 2 rows\n",
    "df = df[df['checking_amt'] != '?'] # removes 1 row\n",
    "\n",
    "# Removes verified as it only has 5 entries and will serve as noise more than anything else\n",
    "del df['verified']\n",
    "\n",
    "# After running chi squared analysis on the nominal attributes:\n",
    "\n",
    "# We noticed that 'works_outside_US' correlated 100% with 'foreign_worker'\n",
    "del df['works_outside_US']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Value renaming - structural modifications to data\n",
    "\"\"\"\n",
    "\n",
    "df['state'] = df['state'].replace('Rhodes Island', 'Rhode Island')\n",
    "\n",
    "# 'location'\n",
    "# Remove state abbrv in location. It is already stored in 'state' column\n",
    "# and has been verified all rows have matching abbrv's and state columns.\n",
    "df['location'] = df['location'].str.replace('District of Columbia', 'District of Columbia, DC')\n",
    "df['location'] = df['location'].str.replace('Prince George\\'s', 'Prince George')\n",
    "df['location'] = df['location'].str.split(', ').apply(lambda x: x[0])\n",
    "\n",
    "# 'property_magnitude'\n",
    "# Replace the ?s with other and make format consistent.\n",
    "df['property_magnitude'] = df['property_magnitude'].mask(df['property_magnitude'] == \"?\", \"no known property\")\n",
    "df['property_magnitude'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# 'class', 'foreign_worker', 'works_outside_US'\n",
    "# Make positive and negative values consistent\n",
    "# df['works_outside_US'].replace(['^(1|[Yy]).*', '^(0|[Nn]).*'], ['YES', 'NO'], inplace=True, regex=True)\n",
    "df['foreign_worker'].replace(['^(1|[Yy]).*', '^(0|[Nn]).*'], ['YES', 'NO'], inplace=True, regex=True)\n",
    "df['class'].replace(['^([Gg]).*', '^([Bb]).*'], ['GOOD', 'BAD'], inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'employment'\n",
    "# Replacing missing employment values with unknown\n",
    "df['employment'] = df['employment'].mask(df['employment'] == \"?\", \"unknown\")\n",
    "#LE = preprocessing.LabelEncoder()\n",
    "#df['employment'] = LE.fit_transform(df['employment'])\n",
    "\n",
    "# 'personal_status'\n",
    "# Replacing missing personal_status values with unknown\n",
    "df['personal_status'] = df['personal_status'].mask(df['personal_status'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['personal_status'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'other_parties'\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['other_parties'] = df['other_parties'].mask(df['other_parties'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_parties'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'purpose'\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['purpose'] = df['purpose'].mask(df['purpose'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['purpose'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'job'\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['job'].mask(df['job'] == \"?\", \"unknown\", inplace=True)\n",
    "# Remove the single quotes around the data\n",
    "df['job'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# 'credit_history'\n",
    "# Replacing missing credit_history values with unknown\n",
    "df['credit_history'] = df['credit_history'].mask(df['credit_history'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['credit_history'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# 'other_payment_plans'\n",
    "# Replacing missing other_payment_plans values with unknown\n",
    "df['other_payment_plans'] = df['other_payment_plans'].mask(df['other_payment_plans'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_payment_plans'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# 'housing'\n",
    "# Replacing missing housing values with unknown\n",
    "df['housing'] = df['housing'].mask(df['housing'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['housing'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# Replacing missing own_telephone values with unknown\n",
    "df['own_telephone'] = df['own_telephone'].mask(df['own_telephone'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['own_telephone'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Value manipulation - semantic modifications to data\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 'checking_amt'\n",
    "# Bin into 10 equal width bins\n",
    "df['checking_amt'] = df['checking_amt'].apply(float) # Stored as strings originally\n",
    "df = df[df['checking_amt'].isna() != True] # removes 1 row\n",
    "if BIN_VALUES:\n",
    "    eqdist_discretiser = EqualWidthDiscretiser(\n",
    "        bins=10, \n",
    "        variables=['checking_amt']\n",
    "    )\n",
    "    df = eqdist_discretiser.fit_transform(df)\n",
    "\n",
    "\n",
    "# 'age'\n",
    "median = df[df['age'] != '?']['age'].apply(int).median()\n",
    "df['age'].mask(df['age'] == \"?\", median, inplace=True)\n",
    "df['age'] = df['age'].apply(int)\n",
    "df = df[df['age'].between(0, 100)]\n",
    "\n",
    "# 'num_dependents'\n",
    "# Set ?'s to median value, remove unrealistic values\n",
    "median = df[df['num_dependents'] != '?']['num_dependents'].apply(int).median()\n",
    "df['num_dependents'].mask(df['num_dependents'] == \"?\", median, inplace=True)\n",
    "df['num_dependents'] = df['num_dependents'].apply(int)\n",
    "df = df[df['num_dependents'].between(0, 5)]\n",
    "\n",
    "# 'duration'\n",
    "# Calculate the median of duration and replace missing values with it\n",
    "median = df[df['duration'] != '?']['duration'].apply(float).median()\n",
    "df['duration'].mask(df['duration'] == \"?\", median, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['duration'] = df['duration'].apply(float)\n",
    "\n",
    "# 'installment_commitment'\n",
    "# Replacing missing installment_commitment values with -1\n",
    "df['installment_commitment'] = df['installment_commitment'].mask(df['installment_commitment'] == \"?\", \"-1\")\n",
    "df['installment_commitment'] = df['installment_commitment'].apply(int)\n",
    "\n",
    "# 'residence_since'\n",
    "# Replacing missing residence_since values with -1\n",
    "df['residence_since'] = df['residence_since'].mask(df['residence_since'] == \"?\", \"-1\")\n",
    "df['residence_since'] = df['residence_since'].apply(int)\n",
    "\n",
    "# 'existing_credits'\n",
    "# Replacing missing existing_credits values with -1\n",
    "df['existing_credits'] = df['existing_credits'].mask(df['existing_credits'] == \"?\", \"-1\")\n",
    "df['existing_credits'] = df['existing_credits'].apply(int)\n",
    "\n",
    "# 'savings'\n",
    "# Calculate the median of savings and replace missing values with it\n",
    "median = df[df['savings'] != '?']['savings'].apply(float).median()\n",
    "df['savings'].mask(df['savings'] == \"?\", median, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['savings'] = df['savings'].apply(float)\n",
    "# Bin by frequency\n",
    "if BIN_VALUES:\n",
    "    df['savings'] = pd.qcut(df['savings'], q=10, duplicates='drop').astype(str) \n",
    "\n",
    "\n",
    "# 'credit_amount'\n",
    "# Grab the credit_amount column without ?s\n",
    "no_miss_credit = df[df['credit_amount'] != \"?\"]\n",
    "# Convert to integer\n",
    "no_miss_credit = no_miss_credit.astype({\"credit_amount\": float})\n",
    "# Remove outliers and then calculate the average value\n",
    "median = float(no_miss_credit['credit_amount'].median())\n",
    "\n",
    "# Remove all ?s with the calculate average, also remove the outliers again\n",
    "df['credit_amount'] = df['credit_amount'].mask(df['credit_amount'] == \"?\", f\"{median}\")\n",
    "df = df.astype({\"credit_amount\": float})\n",
    "\n",
    "# 'application_date'\n",
    "# Clean up the date to follow standard datetime format, then seperate year and month\n",
    "df['application_date']= pd.to_datetime(df['application_date']) \n",
    "df['year'] = df['application_date'].apply(lambda x: datetime.strftime(x.date(), '%Y')).apply(int)\n",
    "df['month'] = df['application_date'].apply(lambda x: datetime.strftime(x.date(), '%m')).apply(int)\n",
    "del df['application_date']\n",
    "\n",
    "\n",
    "\n",
    "# TODO, run attribute grouper first\n",
    "# Most locations only have a few entries\n",
    "# Replace location with other if less than threshold\n",
    "for k, v in df['location'].value_counts().items():\n",
    "    if v < LOC_REPLACE_THRESHOLD:\n",
    "        df['location'].mask(df['location'] == k, \"Other\", inplace=True)\n",
    "\n",
    "\n",
    "# Set decision attribute in last column\n",
    "class_ = df['class']\n",
    "del df['class']\n",
    "df.insert(len(df.columns), 'class', class_)\n",
    "\n",
    "\n",
    "# Output to CSV\n",
    "df.to_csv(DATA_OUTPUT, index=False)\n",
    "\n",
    "# Status of cleaning for each the column\n",
    "\n",
    "# location                # Done\n",
    "# state                   # Done\n",
    "# checking_amt            # binned, want opinion\n",
    "# duration                # TODO 89 '?'s, will get to later, currently replacing missing with median\n",
    "# credit_history          # Done\n",
    "# purpose               # Done\n",
    "# credit_amount         # Done, added average as replacement for missing. Maybe bin?\n",
    "# savings               # Done? maybe don't bin?\n",
    "# employment            # Done\n",
    "# installment_commitment # currently replacing ?s with -1 as a category, may need to change\n",
    "# personal_status       # Done\n",
    "# other_parties         # Done\n",
    "# residence_since       # currently replacing ?s with -1 as a category, may need to change\n",
    "# property_magnitude    # Done, destringified and added \"other\"\n",
    "# age                   # Done, replaced outliers with median of column, filtered out outliers, maybe bin?\n",
    "# other_payment_plans   # Done\n",
    "# housing               # Done\n",
    "# existing_credits      # currently replacing ?s with -1 as a category, may need to change\n",
    "# job                   # Done, replaced ? with unknown\n",
    "# num_dependents        # Done, Removed bad data. Replaced ? with median\n",
    "# own_telephone         # 117 ?'s, Currently just replacing with unknown\n",
    "# foreign_worker        # Done, made yes/no input consistent.\n",
    "# class                 # Done, made good/bad input consistent.\n",
    "# verified              # 995 verified, 3 yes, 2 no. Probably should just drop this.\n",
    "# application_date      # Done. Want opinion. Format as ordinal time or make month/year cols?\n",
    "# works_outside_US      # Done, made yes/no input consistent.\n",
    "\n",
    "# Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "existing paid                     476\n",
       "critical/other existing credit    270\n",
       "unknown                            87\n",
       "delayed previously                 78\n",
       "all paid                           47\n",
       "no credits/all paid                32\n",
       "Name: credit_history, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['purpose'] == 'none']['other_parties'].value_counts()\n",
    "df['credit_history'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting on credit_history\n",
      "\n",
      "\n",
      "[['critical/other existing credit'], ['existing paid'], ['delayed previously'], ['unknown'], ['no credits/all paid'], ['all paid']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on savings\n",
      "\n",
      "\n",
      "[['(-0.001, 7.154]'], ['(65.862, 98.282]'], ['(34.309, 65.862]'], ['(7.154, 34.309]'], ['(98.282, 9298.08]']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on employment\n",
      "\n",
      "\n",
      "[['>=7'], ['1<=X<4'], ['4<=X<7'], ['unknown'], ['unemployed'], ['<1']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on installment_commitment\n",
      "\n",
      "\n",
      "[[-1], [2], [3], [4], [1]]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on personal_status\n",
      "\n",
      "\n",
      "[['male single'], ['female div/dep/mar'], ['male div/sep'], ['male mar/wid'], ['unknown']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on other_parties\n",
      "\n",
      "\n",
      "[['none'], ['unknown'], ['guarantor'], ['co applicant']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on residence_since\n",
      "\n",
      "\n",
      "[[4], [2], [-1], [1], [3]]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on property_magnitude\n",
      "\n",
      "\n",
      "[['real estate'], ['other'], ['life insurance'], ['no known property'], ['car']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on other_payment_plans\n",
      "\n",
      "\n",
      "[['none'], ['unknown'], ['bank'], ['stores']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on housing\n",
      "\n",
      "\n",
      "[['own'], ['unknown'], ['for free'], ['rent']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on existing_credits\n",
      "\n",
      "\n",
      "[[2], [1], [-1], [3], [4]]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on job\n",
      "\n",
      "\n",
      "[['skilled'], ['unskilled resident'], ['high qualif/self emp/mgmt'], ['unknown'], ['unemp/unskilled non res']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on num_dependents\n",
      "\n",
      "\n",
      "[[1], [2]]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on own_telephone\n",
      "\n",
      "\n",
      "[['yes'], ['none'], ['unknown']]\n",
      "-------------------------------------------------\n",
      "\n",
      "Splitting on foreign_worker\n",
      "\n",
      "\n",
      "[['NO'], ['YES']]\n",
      "-------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from attribute_grouper import determine_best_grouping\n",
    "\n",
    "for col in [col for col in df.columns if col != 'class']:\n",
    "    if len(df[col].value_counts()) < 10:\n",
    "        print(f\"Splitting on {col}\\n\\n\")\n",
    "        print(determine_best_grouping(df, col, verbose=False))\n",
    "        print(\"-------------------------------------------------\\n\")\n",
    "\n",
    "# determine_best_grouping(df, 'location', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other             606\n",
       "Los Angeles        45\n",
       "Harris             33\n",
       "Cook               32\n",
       "Wayne              27\n",
       "New York           24\n",
       "Philadelphia       16\n",
       "Dallas             15\n",
       "Clark              15\n",
       "Bexar              15\n",
       "Maricopa           15\n",
       "Fulton             14\n",
       "San Francisco      13\n",
       "Essex              12\n",
       "Baltimore city     12\n",
       "Orleans            12\n",
       "Marion             12\n",
       "Jefferson          11\n",
       "Alameda            10\n",
       "Shelby              9\n",
       "Orange              9\n",
       "San Diego           9\n",
       "Sacramento          8\n",
       "Norfolk             8\n",
       "St. Louis           8\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script.\n",
    "\"\"\"\n",
    "\n",
    "# abbrv_map = {\n",
    "#     'AL': 'Alabama',\n",
    "#     'AK': 'Alaska',\n",
    "#     'AZ': 'Arizona',\n",
    "#     'AR': 'Arkansas',\n",
    "#     'CA': 'California',\n",
    "#     'CO': 'Colorado',\n",
    "#     'CT': 'Connecticut',\n",
    "#     'DE': 'Delaware',\n",
    "#     'DC': 'District of Columbia',\n",
    "#     'FL': 'Florida',\n",
    "#     'GA': 'Georgia',\n",
    "#     'HI': 'Hawaii',\n",
    "#     'ID': 'Idaho',\n",
    "#     'IL': 'Illinois',\n",
    "#     'IN': 'Indiana',\n",
    "#     'IA': 'Iowa',\n",
    "#     'KS': 'Kansas',\n",
    "#     'KY': 'Kentucky',\n",
    "#     'LA': 'Louisiana',\n",
    "#     'ME': 'Maine',\n",
    "#     'MD': 'Maryland',\n",
    "#     'MA': 'Massachusetts',\n",
    "#     'MI': 'Michigan',\n",
    "#     'MN': 'Minnesota',\n",
    "#     'MS': 'Mississippi',\n",
    "#     'MO': 'Missouri',\n",
    "#     'MT': 'Montana',\n",
    "#     'NE': 'Nebraska',\n",
    "#     'NV': 'Nevada',\n",
    "#     'NH': 'New Hampshire',\n",
    "#     'NJ': 'New Jersey',\n",
    "#     'NM': 'New Mexico',\n",
    "#     'NY': 'New York',\n",
    "#     'NC': 'North Carolina',\n",
    "#     'ND': 'North Dakota',\n",
    "#     'OH': 'Ohio',\n",
    "#     'OK': 'Oklahoma',\n",
    "#     'OR': 'Oregon',\n",
    "#     'PA': 'Pennsylvania',\n",
    "#     'RI': 'Rhode Island',\n",
    "#     'SC': 'South Carolina',\n",
    "#     'SD': 'South Dakota',\n",
    "#     'TN': 'Tennessee',\n",
    "#     'TX': 'Texas',\n",
    "#     'UT': 'Utah',\n",
    "#     'VT': 'Vermont',\n",
    "#     'VA': 'Virginia',\n",
    "#     'WA': 'Washington',\n",
    "#     'WV': 'West Virginia',\n",
    "#     'WI': 'Wisconsin',\n",
    "#     'WY': 'Wyoming'\n",
    "# }\n",
    "\n",
    "# def seperate_locs(row):\n",
    "#     \"\"\"\n",
    "#     This was to verify that every location entry had matching state data.\n",
    "#     Long story short they did, so this is not actually needed.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         loc, state_abbrv = row['location'].split(', ')\n",
    "#     except Exception as e:\n",
    "#         print(row['location'])\n",
    "#         raise e\n",
    "#     row['abbrv'] = abbrv_map[state_abbrv]\n",
    "#     row['location'] = loc\n",
    "#     return row['location']\n",
    "# df['abbrv'] = df.apply(seperate_locs, axis=1)\n",
    "\n",
    "\n",
    "df['location'] = df['location'].str.replace('District of Columbia', 'District of Columbia, DC')\n",
    "df['location'] = df['location'].str.split(', ').apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "from feature_engine.discretisers import EqualWidthDiscretiser, EqualFrequencyDiscretiser\n",
    "import matplotlib.pyplot as plt\n",
    "df['checking_amt'] = df['checking_amt'].apply(float) # Stored as strings originally\n",
    "df.hist(column='checking_amt') # Display raw values\n",
    "\n",
    "\n",
    "# Binning is the way to go? Right now I have equal width.\n",
    "# Equal frequency maybe? But I don't think so with the distribution\n",
    "eqdist_discretiser = EqualWidthDiscretiser(\n",
    "    bins=10, \n",
    "    variables=['checking_amt']\n",
    ")\n",
    "df = eqdist_discretiser.fit_transform(df)\n",
    "\n",
    "df.hist(column='checking_amt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['savings'].apply(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none       516\n",
       "yes        357\n",
       "unknown    117\n",
       "Name: own_telephone, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['own_telephone'] = df['own_telephone'].mask(df['own_telephone'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['own_telephone'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['own_telephone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the ?s with other\n",
    "df['property_magnitude'] = df['property_magnitude'].mask(df['property_magnitude'] == \"?\", \"other\")\n",
    "# Remove the single quotes around the data\n",
    "df['property_magnitude'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "# Display the values as a sanity check\n",
    "df['property_magnitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "median = df[df['age'] != '?']['age'].apply(int).median()\n",
    "df['age'].mask(df['age'] == \"?\", median, inplace=True)\n",
    "df['age'] = df['age'].apply(int)\n",
    "df = df[df['age'].between(0, 100)]\n",
    "df.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing employment values with unknown\n",
    "df['employment'] = df['employment'].mask(df['employment'] == \"?\", \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "\n",
    "# Replacing missing personal_status values with unknown\n",
    "df['personal_status'] = df['personal_status'].mask(df['personal_status'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['personal_status'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['other_parties'] = df['other_parties'].mask(df['other_parties'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_parties'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the date to follow standard datetime format\n",
    "df['application_date']= pd.to_datetime(df['application_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the credit_amount column without ?s\n",
    "no_miss_credit = df[df['credit_amount'] != \"?\"]\n",
    "# Convert to integer\n",
    "no_miss_credit = no_miss_credit.astype({\"credit_amount\": float})\n",
    "# Remove outliers and then calculate the average value\n",
    "mean = float(no_miss_credit['credit_amount'].mean())\n",
    "\n",
    "# Remove all ?s with the calculate average, also remove the outliers again\n",
    "df['credit_amount'] = df['credit_amount'].mask(df['credit_amount'] == \"?\", f\"{mean}\")\n",
    "df = df.astype({\"credit_amount\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing purpose values with unknown\n",
    "df['purpose'] = df['purpose'].mask(df['purpose'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['purpose'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from dateutil import parser\n",
    "# Convert to consistent format, set to use ordinal time so it is continious\n",
    "# Do we want that? Loses distinguishing info on month/year but makes continious\n",
    "s = df['application_date'].apply(lambda x: parser.parse(x).date().toordinal())\n",
    "\n",
    "# If we make continious we should also make normalize it.\n",
    "s = (s - s.min())/(s.max() - s.min())\n",
    "\n",
    "df['application_date'] = s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df[df['num_dependents'] != '?']['num_dependents'].apply(int).median()\n",
    "df['num_dependents'].mask(df['num_dependents'] == \"?\", median, inplace=True)\n",
    "df['num_dependents'] = df['num_dependents'].apply(int)\n",
    "df = df[df['num_dependents'].between(0, 5)]\n",
    "df.num_dependents.value_counts()\n",
    "\n",
    "# print(known_vals.mean()) # 2093625.787444934\n",
    "# known_vals = known_vals[known_vals >= 0]\n",
    "# known_vals = known_vals[known_vals <= 5] # The highest valid value seemed to be 2, but 5 just for good measure\n",
    "# # print(known_vals.mean()) # 1.1581858407079646\n",
    "# # print(df[known_vals.index].shape)\n",
    "# known_vals.median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job'].value_counts()\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['job'].mask(df['job'] == \"?\", \"unknown\", inplace=True)\n",
    "# Remove the single quotes around the data\n",
    "df['job'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should NOT be run when we are finished\n",
    "# This naively removes all '?'s just to see some graphs quickly\n",
    "%matplotlib inline\n",
    "for col in numeric_cols:\n",
    "    df = df[df[col] != '?']\n",
    "    df[col] = df[col].apply(float)\n",
    "df.hist(figsize=(20,20))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df[numeric_cols], figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing credit_history values with unknown\n",
    "df['credit_history'] = df['credit_history'].mask(df['credit_history'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['credit_history'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['credit_history'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 7.154]      594\n",
       "(98.282, 9298.08]     99\n",
       "(7.154, 34.309]       99\n",
       "(65.862, 98.282]      99\n",
       "(34.309, 65.862]      99\n",
       "Name: savings, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Calculate the mean of savings and replace missing values with it\n",
    "mean = df[df['savings'] != '?']['savings'].apply(float).mean()\n",
    "df['savings'].mask(df['savings'] == \"?\", mean, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['savings'] = df['savings'].apply(float)\n",
    "# Bin by frequency\n",
    "df['savings'] = pd.qcut(df['savings'], q=10, duplicates='drop').astype(str) \n",
    "df['savings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none       736\n",
       "bank       123\n",
       "unknown     87\n",
       "stores      44\n",
       "Name: other_payment_plans, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing other_payment_plans values with unknown\n",
    "df['other_payment_plans'] = df['other_payment_plans'].mask(df['other_payment_plans'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_payment_plans'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['other_payment_plans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "own         621\n",
       "rent        155\n",
       "unknown     114\n",
       "for free    100\n",
       "Name: housing, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['housing'] = df['housing'].mask(df['housing'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['housing'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['housing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.000000    163\n",
       "24.000000    156\n",
       "18.000000    104\n",
       "20.807991     89\n",
       "36.000000     78\n",
       "6.000000      72\n",
       "15.000000     58\n",
       "9.000000      44\n",
       "48.000000     43\n",
       "30.000000     38\n",
       "21.000000     28\n",
       "10.000000     22\n",
       "27.000000     11\n",
       "60.000000     11\n",
       "42.000000      9\n",
       "11.000000      9\n",
       "20.000000      8\n",
       "8.000000       7\n",
       "4.000000       6\n",
       "45.000000      5\n",
       "7.000000       5\n",
       "39.000000      5\n",
       "28.000000      3\n",
       "14.000000      3\n",
       "22.000000      2\n",
       "54.000000      2\n",
       "33.000000      2\n",
       "13.000000      2\n",
       "40.000000      1\n",
       "16.000000      1\n",
       "5.000000       1\n",
       "26.000000      1\n",
       "72.000000      1\n",
       "Name: duration, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Calculate the mean of duration and replace missing values with it\n",
    "mean = df[df['duration'] != '?']['duration'].apply(float).mean()\n",
    "df['duration'].mask(df['duration'] == \"?\", mean, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['duration'] = df['duration'].apply(float)\n",
    "df['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4    416\n",
       " 2    211\n",
       " 3    129\n",
       " 1    125\n",
       "-1    109\n",
       "Name: installment_commitment, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['installment_commitment'] = df['installment_commitment'].mask(df['installment_commitment'] == \"?\", \"-1\")\n",
    "df['installment_commitment'] = df['installment_commitment'].apply(int)\n",
    "df['installment_commitment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['residence_since'] = df['residence_since'].mask(df['residence_since'] == \"?\", \"-1\")\n",
    "df['residence_since'] = df['residence_since'].apply(int)\n",
    "df['residence_since'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['existing_credits'] = df['existing_credits'].mask(df['existing_credits'] == \"?\", \"-1\")\n",
    "df['existing_credits'] = df['existing_credits'].apply(int)\n",
    "df['existing_credits'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
