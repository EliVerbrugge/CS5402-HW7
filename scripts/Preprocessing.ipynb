{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.discretisers import EqualWidthDiscretiser, EqualFrequencyDiscretiser\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Print all columns to jupyter notebook\n",
    "\n",
    "DATA_PATH = r'../data/credit.csv'\n",
    "DATA_OUTPUT = r'../data/credit_output.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "numeric_cols = [\n",
    "    'checking_amt',\n",
    "    'duration',\n",
    "    'credit_amount',\n",
    "    'savings',\n",
    "    'installment_commitment', # Don't think this is categorical\n",
    "    'residence_since',\n",
    "    'age',\n",
    "    'existing_credits',\n",
    "    'num_dependents'\n",
    "] \n",
    "categorical_cols = list(set(df.columns) - set(numeric_cols))\n",
    "\n",
    "LOC_REPLACE_THRESHOLD = 8\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Remove bad data - Quick removal of rows that contain garbage data\n",
    "\"\"\"\n",
    "# Remove where rows are almost entirely empty\n",
    "df = df[df['location'] != '?'] # removes 2 rows\n",
    "df = df[df['checking_amt'] != '?'] # removes 1 row\n",
    "\n",
    "# Removes verified as it only has 5 entries and will serve as noise more than anything else\n",
    "del df['verified']\n",
    "\n",
    "# After running chi squared analysis on the nominal attributes:\n",
    "\n",
    "# We noticed that 'purpose' correlated 99% with 'other_parties' outside of missing values so it was safe to remove\n",
    "del df['purpose']\n",
    "# We noticed that 'works_outside_US' correlated 100% with 'foreign_worker'\n",
    "del df['works_outside_US']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Value renaming - structural modifications to data\n",
    "\"\"\"\n",
    "\n",
    "df['state'] = df['state'].replace('Rhodes Island', 'Rhode Island')\n",
    "\n",
    "# 'location'\n",
    "# Remove state abbrv in location. It is already stored in 'state' column\n",
    "# and has been verified all rows have matching abbrv's and state columns.\n",
    "df['location'] = df['location'].str.replace('District of Columbia', 'District of Columbia, DC')\n",
    "df['location'] = df['location'].str.replace('Prince George\\'s', 'Prince George')\n",
    "df['location'] = df['location'].str.split(', ').apply(lambda x: x[0])\n",
    "\n",
    "# 'property_magnitude'\n",
    "# Replace the ?s with other and make format consistent.\n",
    "df['property_magnitude'] = df['property_magnitude'].mask(df['property_magnitude'] == \"?\", \"other\")\n",
    "df['property_magnitude'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'class', 'foreign_worker', 'works_outside_US'\n",
    "# Make positive and negative values consistent\n",
    "df['works_outside_US'].replace(['^(1|[Yy]).*', '^(0|[Nn]).*'], ['YES', 'NO'], inplace=True, regex=True)\n",
    "df['foreign_worker'].replace(['^(1|[Yy]).*', '^(0|[Nn]).*'], ['YES', 'NO'], inplace=True, regex=True)\n",
    "df['class'].replace(['^([Gg]).*', '^([Bb]).*'], ['GOOD', 'BAD'], inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'employment'\n",
    "# Replacing missing employment values with unknown\n",
    "df['employment'] = df['employment'].mask(df['employment'] == \"?\", \"unknown\")\n",
    "\n",
    "\n",
    "# 'personal_status'\n",
    "# Replacing missing personal_status values with unknown\n",
    "df['personal_status'] = df['personal_status'].mask(df['personal_status'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['personal_status'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'other_parties'\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['other_parties'] = df['other_parties'].mask(df['other_parties'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_parties'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'purpose'\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['purpose'] = df['other_parties'].mask(df['purpose'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['purpose'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\n",
    "# 'job'\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['job'].mask(df['job'] == \"?\", \"unknown\", inplace=True)\n",
    "# Remove the single quotes around the data\n",
    "df['job'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# 'credit_history'\n",
    "# Replacing missing credit_history values with unknown\n",
    "df['credit_history'] = df['credit_history'].mask(df['credit_history'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['credit_history'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# 'other_payment_plans'\n",
    "# Replacing missing other_payment_plans values with unknown\n",
    "df['other_payment_plans'] = df['other_payment_plans'].mask(df['other_payment_plans'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_payment_plans'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# 'housing'\n",
    "# Replacing missing housing values with unknown\n",
    "df['housing'] = df['housing'].mask(df['housing'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['housing'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "# Replacing missing own_telephone values with unknown\n",
    "df['own_telephone'] = df['own_telephone'].mask(df['own_telephone'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['own_telephone'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "\n",
    "\"\"\"\n",
    "Value manipulation - semantic modifications to data\n",
    "\"\"\"\n",
    "\n",
    "# 'checking_amt'\n",
    "# Bin into 10 equal width bins\n",
    "df['checking_amt'] = df['checking_amt'].apply(float) # Stored as strings originally\n",
    "df = df[df['checking_amt'].isna() != True] # removes 1 row\n",
    "eqdist_discretiser = EqualWidthDiscretiser(\n",
    "    bins=10, \n",
    "    variables=['checking_amt']\n",
    ")\n",
    "df = eqdist_discretiser.fit_transform(df)\n",
    "\n",
    "\n",
    "# 'age'\n",
    "median = df[df['age'] != '?']['age'].apply(int).median()\n",
    "df['age'].mask(df['age'] == \"?\", median, inplace=True)\n",
    "df['age'] = df['age'].apply(int)\n",
    "df = df[df['age'].between(0, 100)]\n",
    "\n",
    "# 'num_dependents'\n",
    "# Set ?'s to median value, remove unrealistic values\n",
    "median = df[df['num_dependents'] != '?']['num_dependents'].apply(int).median()\n",
    "df['num_dependents'].mask(df['num_dependents'] == \"?\", median, inplace=True)\n",
    "df['num_dependents'] = df['num_dependents'].apply(int)\n",
    "df = df[df['num_dependents'].between(0, 5)]\n",
    "\n",
    "# 'duration'\n",
    "# Calculate the median of duration and replace missing values with it\n",
    "median = df[df['duration'] != '?']['duration'].apply(float).median()\n",
    "df['duration'].mask(df['duration'] == \"?\", median, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['duration'] = df['duration'].apply(float)\n",
    "\n",
    "# 'installment_commitment'\n",
    "# Replacing missing installment_commitment values with -1\n",
    "df['installment_commitment'] = df['installment_commitment'].mask(df['installment_commitment'] == \"?\", \"-1\")\n",
    "df['installment_commitment'] = df['installment_commitment'].apply(int)\n",
    "\n",
    "# 'residence_since'\n",
    "# Replacing missing residence_since values with -1\n",
    "df['residence_since'] = df['residence_since'].mask(df['residence_since'] == \"?\", \"-1\")\n",
    "df['residence_since'] = df['residence_since'].apply(int)\n",
    "\n",
    "# 'existing_credits'\n",
    "# Replacing missing existing_credits values with -1\n",
    "df['existing_credits'] = df['existing_credits'].mask(df['existing_credits'] == \"?\", \"-1\")\n",
    "df['existing_credits'] = df['existing_credits'].apply(int)\n",
    "\n",
    "# 'savings'\n",
    "# Calculate the median of savings and replace missing values with it\n",
    "median = df[df['savings'] != '?']['savings'].apply(float).median()\n",
    "df['savings'].mask(df['savings'] == \"?\", median, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['savings'] = df['savings'].apply(float)\n",
    "# Bin by frequency\n",
    "df['savings'] = pd.qcut(df['savings'], q=10, duplicates='drop').astype(str) \n",
    "\n",
    "\n",
    "# 'credit_amount'\n",
    "# Grab the credit_amount column without ?s\n",
    "no_miss_credit = df[df['credit_amount'] != \"?\"]\n",
    "# Convert to integer\n",
    "no_miss_credit = no_miss_credit.astype({\"credit_amount\": float})\n",
    "# Remove outliers and then calculate the average value\n",
    "median = float(no_miss_credit['credit_amount'].median())\n",
    "\n",
    "# Remove all ?s with the calculate average, also remove the outliers again\n",
    "df['credit_amount'] = df['credit_amount'].mask(df['credit_amount'] == \"?\", f\"{median}\")\n",
    "df = df.astype({\"credit_amount\": float})\n",
    "\n",
    "# 'application_date'\n",
    "# Clean up the date to follow standard datetime format\n",
    "df['application_date']= pd.to_datetime(df['application_date']) \n",
    "\n",
    "\n",
    "# TODO, run attribute grouper first\n",
    "# # Most locations only have a few entries\n",
    "# # Replace location with other if less than threshold\n",
    "# for k, v in df['location'].value_counts().items():\n",
    "#     if v < LOC_REPLACE_THRESHOLD:\n",
    "#         df[df['location']  == k] = 'Other'\n",
    "\n",
    "\n",
    "# Set decision attribute in last column\n",
    "class_ = df['class']\n",
    "del df['class']\n",
    "df.insert(len(df.columns), 'class', class_)\n",
    "\n",
    "\n",
    "def simplify_location(row):\n",
    "    if \n",
    "\n",
    "# Output to CSV\n",
    "df.to_csv(DATA_OUTPUT, index=False)\n",
    "\n",
    "# Status of cleaning for each the column\n",
    "\n",
    "# location                # Done\n",
    "# state                   # Done\n",
    "# checking_amt            # binned, want opinion\n",
    "# duration                # TODO 89 '?'s, will get to later, currently replacing missing with median\n",
    "# credit_history          # Done\n",
    "# purpose               # Done\n",
    "# credit_amount         # Done, added average as replacement for missing. Maybe bin?\n",
    "# savings               # Done? maybe don't bin?\n",
    "# employment            # Done\n",
    "# installment_commitment # currently replacing ?s with -1 as a category, may need to change\n",
    "# personal_status       # Done\n",
    "# other_parties         # Done\n",
    "# residence_since       # currently replacing ?s with -1 as a category, may need to change\n",
    "# property_magnitude    # Done, destringified and added \"other\"\n",
    "# age                   # Done, replaced outliers with median of column, filtered out outliers, maybe bin?\n",
    "# other_payment_plans   # Done\n",
    "# housing               # Done\n",
    "# existing_credits      # currently replacing ?s with -1 as a category, may need to change\n",
    "# job                   # Done, replaced ? with unknown\n",
    "# num_dependents        # Done, Removed bad data. Replaced ? with median\n",
    "# own_telephone         # 117 ?'s, Currently just replacing with unknown\n",
    "# foreign_worker        # Done, made yes/no input consistent.\n",
    "# class                 # Done, made good/bad input consistent.\n",
    "# verified              # 995 verified, 3 yes, 2 no. Probably should just drop this.\n",
    "# application_date      # Done. Want opinion. Format as ordinal time or make month/year cols?\n",
    "# works_outside_US      # Done, made yes/no input consistent.\n",
    "\n",
    "# Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los Angeles              : 45\n",
      "Harris                   : 33\n",
      "Cook                     : 32\n",
      "Wayne                    : 27\n",
      "New York                 : 24\n",
      "Philadelphia             : 16\n",
      "Maricopa                 : 15\n",
      "Bexar                    : 15\n",
      "Dallas                   : 15\n",
      "Clark                    : 15\n",
      "Fulton                   : 14\n",
      "San Francisco            : 13\n",
      "Marion                   : 12\n",
      "Orleans                  : 12\n",
      "Essex                    : 12\n",
      "Baltimore city           : 12\n",
      "Jefferson                : 11\n",
      "Alameda                  : 10\n",
      "Shelby                   : 9\n",
      "San Diego                : 9\n",
      "Orange                   : 9\n",
      "Sacramento               : 8\n",
      "St. Louis                : 8\n",
      "Norfolk                  : 8\n",
      "Cuyahoga                 : 7\n",
      "San Bernardino           : 7\n",
      "Madison                  : 7\n",
      "El Paso                  : 7\n",
      "Suffolk                  : 7\n",
      "De Kalb                  : 7\n",
      "Camden                   : 6\n",
      "District of Columbia     : 6\n",
      "Monroe                   : 6\n",
      "Travis                   : 6\n",
      "Contra Costa             : 6\n",
      "Davidson                 : 5\n",
      "Erie                     : 5\n",
      "Richmond                 : 5\n",
      "Milwaukee                : 5\n",
      "Palm Beach               : 5\n",
      "Charleston               : 5\n",
      "Greenville               : 5\n",
      "Tarrant                  : 5\n",
      "Chatham                  : 5\n",
      "Franklin                 : 5\n",
      "Miami-Dade               : 5\n",
      "Jackson                  : 5\n",
      "Middlesex                : 5\n",
      "Hinds                    : 4\n",
      "Monterey                 : 4\n",
      "Spokane                  : 4\n",
      "Mecklenburg              : 4\n",
      "Broward                  : 4\n",
      "Hillsborough             : 4\n",
      "Russell                  : 4\n",
      "Anderson                 : 4\n",
      "Hughes                   : 4\n",
      "Boone                    : 4\n",
      "Fresno                   : 4\n",
      "Parke                    : 4\n",
      "St. Clair                : 4\n",
      "Passaic                  : 4\n",
      "Kern                     : 4\n",
      "Jasper                   : 4\n",
      "Polk                     : 4\n",
      "Greene                   : 4\n",
      "Brevard                  : 4\n",
      "Bernalillo               : 3\n",
      "Macomb                   : 3\n",
      "Prince William           : 3\n",
      "Richland                 : 3\n",
      "Clayton                  : 3\n",
      "Dauphin                  : 3\n",
      "Perry                    : 3\n",
      "Denver                   : 3\n",
      "Santa Clara              : 3\n",
      "King                     : 3\n",
      "Hidalgo                  : 3\n",
      "New Castle               : 3\n",
      "Spartanburg              : 3\n",
      "Fayette                  : 3\n",
      "Hamilton                 : 3\n",
      "Prince George            : 3\n",
      "Horry                    : 3\n",
      "Pima                     : 3\n",
      "Multnomah                : 3\n",
      "Logan                    : 3\n",
      "Jefferson City           : 3\n",
      "Salt Lake                : 3\n",
      "Daviess                  : 3\n",
      "Chicago                  : 3\n",
      "Caddo                    : 3\n",
      "Anne Arundel             : 3\n",
      "San Joaquin              : 3\n",
      "Pinellas                 : 3\n",
      "Nueces                   : 3\n",
      "Kansas City              : 3\n",
      "East Baton Rouge         : 3\n",
      "Summit                   : 3\n",
      "St. Joseph               : 3\n",
      "Mercer                   : 3\n",
      "Williamson               : 2\n",
      "Onondaga                 : 2\n",
      "Ventura                  : 2\n",
      "Robertson                : 2\n",
      "Pulaski                  : 2\n",
      "Kanawha                  : 2\n",
      "Bell                     : 2\n",
      "Westmoreland             : 2\n",
      "Washoe                   : 2\n",
      "Providence               : 2\n",
      "Solano                   : 2\n",
      "Yolo                     : 2\n",
      "Bay                      : 2\n",
      "DuPage                   : 2\n",
      "Phillips                 : 2\n",
      "Nevada                   : 2\n",
      "Buckingham               : 2\n",
      "Pierce                   : 2\n",
      "Kane                     : 2\n",
      "Henry                    : 2\n",
      "Montgomery               : 2\n",
      "Hunt                     : 2\n",
      "Taylor                   : 2\n",
      "Lexington                : 2\n",
      "Haywood                  : 2\n",
      "Honolulu                 : 2\n",
      "San Mateo                : 2\n",
      "Portsmouth               : 2\n",
      "Hartford                 : 2\n",
      "Muscogee                 : 2\n",
      "Union                    : 2\n",
      "Guilford                 : 2\n",
      "Potter                   : 2\n",
      "Kitsap                   : 2\n",
      "St. Martin               : 2\n",
      "Dillon                   : 2\n",
      "Dougherty                : 2\n",
      "Hampden                  : 2\n",
      "Newport News             : 2\n",
      "Mahoning                 : 2\n",
      "Houston                  : 2\n",
      "Anchorage                : 2\n",
      "Adams                    : 2\n",
      "Knox                     : 2\n",
      "Lucas                    : 2\n",
      "Chester                  : 2\n",
      "Stanton                  : 2\n",
      "Rolla                    : 2\n",
      "Washington               : 2\n",
      "Nash                     : 2\n",
      "Allegheny                : 2\n",
      "Floyd                    : 2\n",
      "Forrest                  : 2\n",
      "Northampton              : 2\n",
      "Stanislaus               : 2\n",
      "Linn                     : 2\n",
      "San Jose                 : 2\n",
      "Saginaw                  : 2\n",
      "Canyon                   : 2\n",
      "Lake                     : 2\n",
      "Accomack                 : 2\n",
      "Bradley                  : 2\n",
      "Whatcom                  : 1\n",
      "Wharton                  : 1\n",
      "Williamsburg             : 1\n",
      "James City               : 1\n",
      "Vanderburgh              : 1\n",
      "Macon                    : 1\n",
      "Larue                    : 1\n",
      "Volusia                  : 1\n",
      "Florence                 : 1\n",
      "Dona Ana                 : 1\n",
      "Hale                     : 1\n",
      "Frederick                : 1\n",
      "Virginia Beach           : 1\n",
      "Benton                   : 1\n",
      "Terrell                  : 1\n",
      "Culpeper                 : 1\n",
      "Bullitt                  : 1\n",
      "Blount                   : 1\n",
      "York                     : 1\n",
      "Escambia                 : 1\n",
      "Kingdom City             : 1\n",
      "Asotin                   : 1\n",
      "Butler                   : 1\n",
      "Lauderdale               : 1\n",
      "Lancaster                : 1\n",
      "Hopkins                  : 1\n",
      "Mississippi              : 1\n",
      "Gadsden                  : 1\n",
      "Whitley                  : 1\n",
      "Kenosha                  : 1\n",
      "Raleigh                  : 1\n",
      "Garland                  : 1\n",
      "Atlantic                 : 1\n",
      "Mifflin                  : 1\n",
      "Seward                   : 1\n",
      "Galveston                : 1\n",
      "Terrebonne               : 1\n",
      "Spalding                 : 1\n",
      "Pottawattamie            : 1\n",
      "Lafourche                : 1\n",
      "St. Charles              : 1\n",
      "St. Tammany              : 1\n",
      "Baker                    : 1\n",
      "Cass                     : 1\n",
      "Berrien                  : 1\n",
      "McLean                   : 1\n",
      "Duval                    : 1\n",
      "Greenwood                : 1\n",
      "Gregg                    : 1\n",
      "Chippewa                 : 1\n",
      "Sabine                   : 1\n",
      "Riverside                : 1\n",
      "Imperial                 : 1\n",
      "Stark                    : 1\n",
      "Humboldt                 : 1\n",
      "Elbert                   : 1\n",
      "Sumter                   : 1\n",
      "Concordia                : 1\n",
      "Pasco                    : 1\n",
      "Stevens                  : 1\n",
      "Knott                    : 1\n",
      "Merced                   : 1\n",
      "Otero                    : 1\n",
      "Barnstable               : 1\n",
      "Midland                  : 1\n",
      "Woodruff                 : 1\n",
      "Berkshire                : 1\n",
      "Saline                   : 1\n",
      "Charles                  : 1\n",
      "Medina                   : 1\n",
      "Ouachita                 : 1\n",
      "Tallapoosa               : 1\n",
      "Vernon                   : 1\n",
      "Elkhart                  : 1\n",
      "Bristol                  : 1\n",
      "Wyandotte                : 1\n",
      "Rapides                  : 1\n",
      "Denton                   : 1\n",
      "Pike                     : 1\n",
      "Sonoma                   : 1\n",
      "Christian                : 1\n",
      "Sangamon                 : 1\n",
      "Minnehaha                : 1\n",
      "Trigg                    : 1\n",
      "Huron                    : 1\n",
      "Snohomish                : 1\n",
      "Patrick                  : 1\n",
      "Montague                 : 1\n",
      "Barren                   : 1\n",
      "Wood                     : 1\n",
      "St. Lucie                : 1\n",
      "Yuma                     : 1\n",
      "Sevier                   : 1\n",
      "Owen                     : 1\n",
      "Marshall                 : 1\n",
      "Baltimore                : 1\n",
      "Bastrop                  : 1\n",
      "Pittsylvania             : 1\n",
      "Fentress                 : 1\n",
      "Tangipahoa               : 1\n",
      "Palo Alto                : 1\n",
      "Winston                  : 1\n",
      "Crawford                 : 1\n",
      "Talbot                   : 1\n",
      "Lee                      : 1\n",
      "Bossier                  : 1\n",
      "San Luis Obispo          : 1\n",
      "Collier                  : 1\n",
      "Seminole                 : 1\n",
      "Tipton                   : 1\n",
      "Harlan                   : 1\n",
      "Springfield              : 1\n",
      "Albany                   : 1\n",
      "Tulare                   : 1\n",
      "Champaign                : 1\n",
      "New Haven                : 1\n",
      "Winnebago                : 1\n",
      "East Carroll             : 1\n",
      "Noble                    : 1\n",
      "Lehigh                   : 1\n",
      "Vermilion                : 1\n",
      "Cumberland               : 1\n",
      "Gwinnett                 : 1\n",
      "Nassau                   : 1\n",
      "Genesee                  : 1\n",
      "Cobb                     : 1\n",
      "Dunn                     : 1\n",
      "Kalamazoo                : 1\n",
      "Red River                : 1\n",
      "Somerset                 : 1\n",
      "Kankakee                 : 1\n",
      "Collin                   : 1\n",
      "St. John the Baptist     : 1\n",
      "Pitt                     : 1\n",
      "Johnson                  : 1\n",
      "Harrison                 : 1\n",
      "Rockcastle               : 1\n",
      "Bourbon                  : 1\n",
      "Orangeburg               : 1\n",
      "McLennan                 : 1\n",
      "Worcester                : 1\n",
      "Chaves                   : 1\n",
      "McNairy                  : 1\n",
      "Burlington               : 1\n",
      "Rock                     : 1\n",
      "Ashley                   : 1\n",
      "Fairfield                : 1\n",
      "Breathitt                : 1\n",
      "Yakima                   : 1\n",
      "St. Louis city           : 1\n",
      "Skagit                   : 1\n",
      "Yavapai                  : 1\n",
      "Aiken                    : 1\n",
      "Fort Worth               : 1\n",
      "McKinley                 : 1\n",
      "Brown                    : 1\n",
      "Racine                   : 1\n",
      "Lynchburg                : 1\n",
      "Claiborne                : 1\n",
      "Delaware                 : 1\n",
      "Baldwin                  : 1\n",
      "Danville                 : 1\n",
      "Kent                     : 1\n",
      "Toombs                   : 1\n",
      "Carroll                  : 1\n",
      "Ingham                   : 1\n",
      "Coconino                 : 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS9klEQVR4nO3df4xl5X3f8fen4B+xp2HB64zo7rZDauKIsLFrppSIqpoxSbM2lpc/kAsiyW5KNWpLXNpg2Yv7B20lVNxWcRyljbQNiLVqMaaYBgRxW0KY0kgFZ9d2vPyw6y0Ge1eYrQVsMo6Ktc63f8zZZLR37vy682uf+35JqznnOc8555nvznzm6Lnn3pOqQpLUlr+02QOQJK09w12SGmS4S1KDDHdJapDhLkkNOn+zBwCwffv2GhsbW7TP97//fd7+9rdvzIDOEdaklzXpZU16tVKTI0eOfK+q3rnQti0R7mNjYxw+fHjRPjMzM0xMTGzMgM4R1qSXNellTXq1UpMkL/Xb5rSMJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aEu8Q3UQYwce7bvtxbuu3cCRSNLW4ZW7JDXIcJekBhnuktQgw12SGrRkuCe5J8nJJM+c1f7RJF9P8mySfzOv/fYkx5J8I8nPr8egJUmLW87dMvcCvwl89kxDkklgL/CeqnojyY917ZcBNwA/BfwV4PeS/ERV/XCtBy5J6m/JK/eqehJ49azmfwTcVVVvdH1Odu17gemqeqOqvgUcA65cw/FKkpYhVbV0p2QMeKSqLu/Wvwo8BOwB/h/wsar6wyS/CTxVVf+p63c38MWqemCBY04BUwCjo6NXTE9PLzqG2dlZRkZGetqPnjjVd5/dOy5Y8ns7l/WryTCzJr2sSa9WajI5OXmkqsYX2rbaNzGdD1wEXAX8TeD+JD++kgNU1UHgIMD4+Hgt9cirfo/F2r/Ym5huWvyY57pWHhW2lqxJL2vSaxhqstq7ZY4DD9acLwF/BmwHTgC75vXb2bVJkjbQasP9d4BJgCQ/AbwZ+B7wMHBDkrckuQS4FPjSGoxTkrQCS07LJLkPmAC2JzkO3AHcA9zT3R75A2BfzU3eP5vkfuA54DRwi3fKSNLGWzLcq+rGPpt+oU//O4E7BxmUJGkwvkNVkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgJcM9yT1JTnZPXTp7221JKsn2bj1JfiPJsSRfS/K+9Ri0JGlxy7lyvxfYc3Zjkl3A3wW+Pa/5A8w9N/VSYAr4rcGHKElaqSXDvaqeBF5dYNOngY8DNa9tL/DZmvMUsC3JxWsyUknSsi35DNWFJNkLnKiqP0oyf9MO4Dvz1o93bS8vcIwp5q7uGR0dZWZmZtFzzs7OLtjntt2n++6z1DHPdf1qMsysSS9r0msYarLicE/yNuCTzE3JrFpVHQQOAoyPj9fExMSi/WdmZlioz/4Dj/bd58WbFj/mua5fTYaZNellTXoNQ01Wc+X+14FLgDNX7TuBLye5EjgB7JrXd2fXJknaQCu+FbKqjlbVj1XVWFWNMTf18r6q+i7wMPBL3V0zVwGnqqpnSkaStL6WcyvkfcD/At6d5HiSmxfp/rvAC8Ax4D8C/3hNRilJWpElp2Wq6sYlto/NWy7glsGHJUkahO9QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aDlPYronyckkz8xr+7dJvp7ka0n+S5Jt87bdnuRYkm8k+fl1GrckaRHLuXK/F9hzVttjwOVV9dPA/wZuB0hyGXAD8FPdPv8hyXlrNlpJ0rIsGe5V9STw6llt/72qTnerTwE7u+W9wHRVvVFV32LuWapXruF4JUnLsOQzVJfh7wOf75Z3MBf2Zxzv2nokmQKmAEZHR5mZmVn0JLOzswv2uW336d7OnaWOea7rV5NhZk16WZNew1CTgcI9yT8HTgOfW+m+VXUQOAgwPj5eExMTi/afmZlhoT77Dzzad58Xb1r8mOe6fjUZZtaklzXpNQw1WXW4J9kPfAi4pqqqaz4B7JrXbWfXJknaQKu6FTLJHuDjwIer6k/nbXoYuCHJW5JcAlwKfGnwYUqSVmLJK/ck9wETwPYkx4E7mLs75i3AY0kAnqqqf1hVzya5H3iOuemaW6rqh+s1eEnSwpYM96q6cYHmuxfpfydw5yCDkiQNxneoSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIatGS4J7knyckkz8xruyjJY0m+2X29sGtPkt9IcizJ15K8bz0HL0la2HKu3O8F9pzVdgB4vKouBR7v1gE+wNxzUy8FpoDfWpthSpJWYslwr6ongVfPat4LHOqWDwHXzWv/bM15CtiW5OI1GqskaZlSVUt3SsaAR6rq8m799ara1i0HeK2qtiV5BLirqv6g2/Y48ImqOrzAMaeYu7pndHT0iunp6UXHMDs7y8jISE/70ROn+u6ze8cFS35v57J+NRlm1qSXNenVSk0mJyePVNX4QtuWfED2Uqqqkiz9F6J3v4PAQYDx8fGamJhYtP/MzAwL9dl/4NG++7x40+LHPNf1q8kwsya9rEmvYajJau+WeeXMdEv39WTXfgLYNa/fzq5NkrSBVhvuDwP7uuV9wEPz2n+pu2vmKuBUVb084BglSSu05LRMkvuACWB7kuPAHcBdwP1JbgZeAj7Sdf9d4IPAMeBPgV9ehzFLkpawZLhX1Y19Nl2zQN8Cbhl0UJKkwfgOVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkho0ULgn+WdJnk3yTJL7krw1ySVJnk5yLMnnk7x5rQYrSVqeVYd7kh3APwHGq+py4DzgBuBTwKer6l3Aa8DNazFQSdLyDTotcz7wI0nOB94GvAy8H3ig234IuG7Ac0iSVmjV4V5VJ4B/B3ybuVA/BRwBXq+q012348COQQcpSVqZzD32dBU7JhcCXwD+HvA68J+Zu2L/F92UDEl2AV/spm3O3n8KmAIYHR29Ynp6etHzzc7OMjIy0tN+9MSpvvvs3nHB8r6Zc1S/mgwza9LLmvRqpSaTk5NHqmp8oW1LPiB7ET8LfKuq/i9AkgeBq4FtSc7vrt53AicW2rmqDgIHAcbHx2tiYmLRk83MzLBQn/0HHu27z4s3LX7Mc12/mgwza9LLmvQahpoMMuf+beCqJG9LEuAa4DngCeD6rs8+4KHBhihJWqlB5tyfZm4a5svA0e5YB4FPAL+a5BjwDuDuNRinJGkFBpmWoaruAO44q/kF4MpBjitJGozvUJWkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNWigcE+yLckDSb6e5PkkP5PkoiSPJflm9/XCtRqsJGl5BnoSE/AZ4L9W1fVJ3gy8Dfgk8HhV3ZXkAHCAuUfvbbixPg/PfvGuazd4JJK0sVZ95Z7kAuDv0D0jtap+UFWvA3uBQ123Q8B1gw1RkrRSqarV7Zi8l7kHYj8HvAc4AtwKnKiqbV2fAK+dWT9r/ylgCmB0dPSK6enpRc83OzvLyMhIT/vRE6dWPPbdOy5Y8T5bUb+aDDNr0sua9GqlJpOTk0eqanyhbYOE+zjwFHB1VT2d5DPAHwMfnR/mSV6rqkXn3cfHx+vw4cOLnm9mZoaJiYme9n5TL4tpZVqmX02GmTXpZU16tVKTJH3DfZAXVI8Dx6vq6W79AeB9wCtJLu5OfDFwcoBzSJJWYdXhXlXfBb6T5N1d0zXMTdE8DOzr2vYBDw00QknSig16t8xHgc91d8q8APwyc38w7k9yM/AS8JEBzyFJWqGBwr2qvgosNN9zzSDHlSQNxneoSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaNHC4JzkvyVeSPNKtX5Lk6STHkny+e0qTJGkDrcWV+63A8/PWPwV8uqreBbwG3LwG55AkrcBA4Z5kJ3At8NvdeoD3Aw90XQ4B1w1yDknSyqWqVr9z8gDwr4G/DHwM2A881V21k2QX8MWqunyBfaeAKYDR0dErpqenFz3X7OwsIyMjPe1HT5xa8bh377hgxftsRf1qMsysSS9r0quVmkxOTh6pqoWeY736B2Qn+RBwsqqOJJlY6f5VdRA4CDA+Pl4TE4sfYmZmhoX67D/w6EpPzYs3LX6uc0W/mgwza9LLmvQahpqsOtyBq4EPJ/kg8FbgR4HPANuSnF9Vp4GdwInBhylJWolVz7lX1e1VtbOqxoAbgN+vqpuAJ4Dru277gIcGHqUkaUXW4z73TwC/muQY8A7g7nU4hyRpEYNMy/y5qpoBZrrlF4Ar1+K4kqTV8R2qktQgw12SGrQm0zLnmrE+t0++eNe1GzwSSVofXrlLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aNXhnmRXkieSPJfk2SS3du0XJXksyTe7rxeu3XAlScsxyJX7aeC2qroMuAq4JcllwAHg8aq6FHi8W5ckbaBBHpD9clV9uVv+E+B5YAewFzjUdTsEXDfgGCVJK5SqGvwgyRjwJHA58O2q2ta1B3jtzPpZ+0wBUwCjo6NXTE9PL3qO2dlZRkZGetqPnjg12ODn2b3jgjU71kboV5NhZk16WZNerdRkcnLySFWNL7Rt4HBPMgL8D+DOqnowyevzwzzJa1W16Lz7+Ph4HT58eNHzzMzMMDEx0dPe76lKa2mrPqGpX02GmTXpZU16tVKTJH3DfaC7ZZK8CfgC8LmqerBrfiXJxd32i4GTg5xDkrRyg9wtE+Bu4Pmq+rV5mx4G9nXL+4CHVj88SdJqDPKA7KuBXwSOJvlq1/ZJ4C7g/iQ3Ay8BHxlohJKkFVt1uFfVHwDps/ma1R5XkjQ436EqSQ0y3CWpQYa7JDVokBdUh0a/e+m36v3vkuSVuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDfI+93XgffGSNptX7pLUIK/cB7ART4GSpNUw3IfAYn+EVjpV5JSTdG4w3DfQSoPRIJW0Wus2555kT5JvJDmW5MB6nUeS1Gtdwj3JecC/Bz4AXAbcmOSy9TiXJKnXek3LXAkcq6oXAJJMA3uB59bpfEPlzHTNbbtPs3/AF3XX+0XhlqeW1up722o1Ws3PRAv/n+tto/+fU1Vrf9DkemBPVf2Dbv0Xgb9VVb8yr88UMNWtvhv4xhKH3Q58b80He26zJr2sSS9r0quVmvy1qnrnQhs27QXVqjoIHFxu/ySHq2p8HYd0zrEmvaxJL2vSaxhqsl4vqJ4Ads1b39m1SZI2wHqF+x8Clya5JMmbgRuAh9fpXJKks6zLtExVnU7yK8B/A84D7qmqZwc87LKncIaINellTXpZk17N12RdXlCVJG0uPzhMkhpkuEtSg7Z8uPsxBpDkniQnkzwzr+2iJI8l+Wb39cLNHONGS7IryRNJnkvybJJbu/Zhr8tbk3wpyR91dfmXXfslSZ7ufo8+393oMDSSnJfkK0ke6dabr8eWDnc/xuDP3QvsOavtAPB4VV0KPN6tD5PTwG1VdRlwFXBL97Mx7HV5A3h/Vb0HeC+wJ8lVwKeAT1fVu4DXgJs3b4ib4lbg+XnrzddjS4c78z7GoKp+AJz5GIOhUlVPAq+e1bwXONQtHwKu28gxbbaqermqvtwt/wlzv7g7sC5VVbPd6pu6fwW8H3igax+quiTZCVwL/Ha3HoagHls93HcA35m3frxrE4xW1cvd8neB0c0czGZKMgb8DeBprMuZKYivAieBx4D/A7xeVae7LsP2e/TrwMeBP+vW38EQ1GOrh7uWoebuZx3Ke1qTjABfAP5pVf3x/G3DWpeq+mFVvZe5d4ZfCfzk5o5o8yT5EHCyqo5s9lg22lZ/WIcfY9DfK0kurqqXk1zM3FXaUEnyJuaC/XNV9WDXPPR1OaOqXk/yBPAzwLYk53dXq8P0e3Q18OEkHwTeCvwo8BmGoB5b/crdjzHo72FgX7e8D3hoE8ey4bp507uB56vq1+ZtGva6vDPJtm75R4CfY+71iCeA67tuQ1OXqrq9qnZW1Rhz+fH7VXUTQ1CPLf8O1e4v7q/zFx9jcOfmjmjjJbkPmGDuY0pfAe4Afge4H/irwEvAR6rq7Bddm5XkbwP/EzjKX8ylfpK5efdhrstPM/cC4XnMXbzdX1X/KsmPM3dDwkXAV4BfqKo3Nm+kGy/JBPCxqvrQMNRjy4e7JGnltvq0jCRpFQx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KD/D37LCBFzUsjFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in df['location'].value_counts().items():\n",
    "    print(f'{k:<25}: {v}')\n",
    "\n",
    "df['location'].value_counts().hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other             606\n",
       "Los Angeles        45\n",
       "Harris             33\n",
       "Cook               32\n",
       "Wayne              27\n",
       "New York           24\n",
       "Philadelphia       16\n",
       "Bexar              15\n",
       "Clark              15\n",
       "Dallas             15\n",
       "Maricopa           15\n",
       "Fulton             14\n",
       "San Francisco      13\n",
       "Essex              12\n",
       "Marion             12\n",
       "Baltimore city     12\n",
       "Orleans            12\n",
       "Jefferson          11\n",
       "Alameda            10\n",
       "San Diego           9\n",
       "Orange              9\n",
       "Shelby              9\n",
       "St. Louis           8\n",
       "Sacramento          8\n",
       "Norfolk             8\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 8\n",
    "\n",
    "for k, v in df['location'].value_counts().items():\n",
    "    if v < THRESHOLD:\n",
    "        df[df['location']  == k] = 'Other'\n",
    "\n",
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script.\n",
    "\"\"\"\n",
    "\n",
    "# abbrv_map = {\n",
    "#     'AL': 'Alabama',\n",
    "#     'AK': 'Alaska',\n",
    "#     'AZ': 'Arizona',\n",
    "#     'AR': 'Arkansas',\n",
    "#     'CA': 'California',\n",
    "#     'CO': 'Colorado',\n",
    "#     'CT': 'Connecticut',\n",
    "#     'DE': 'Delaware',\n",
    "#     'DC': 'District of Columbia',\n",
    "#     'FL': 'Florida',\n",
    "#     'GA': 'Georgia',\n",
    "#     'HI': 'Hawaii',\n",
    "#     'ID': 'Idaho',\n",
    "#     'IL': 'Illinois',\n",
    "#     'IN': 'Indiana',\n",
    "#     'IA': 'Iowa',\n",
    "#     'KS': 'Kansas',\n",
    "#     'KY': 'Kentucky',\n",
    "#     'LA': 'Louisiana',\n",
    "#     'ME': 'Maine',\n",
    "#     'MD': 'Maryland',\n",
    "#     'MA': 'Massachusetts',\n",
    "#     'MI': 'Michigan',\n",
    "#     'MN': 'Minnesota',\n",
    "#     'MS': 'Mississippi',\n",
    "#     'MO': 'Missouri',\n",
    "#     'MT': 'Montana',\n",
    "#     'NE': 'Nebraska',\n",
    "#     'NV': 'Nevada',\n",
    "#     'NH': 'New Hampshire',\n",
    "#     'NJ': 'New Jersey',\n",
    "#     'NM': 'New Mexico',\n",
    "#     'NY': 'New York',\n",
    "#     'NC': 'North Carolina',\n",
    "#     'ND': 'North Dakota',\n",
    "#     'OH': 'Ohio',\n",
    "#     'OK': 'Oklahoma',\n",
    "#     'OR': 'Oregon',\n",
    "#     'PA': 'Pennsylvania',\n",
    "#     'RI': 'Rhode Island',\n",
    "#     'SC': 'South Carolina',\n",
    "#     'SD': 'South Dakota',\n",
    "#     'TN': 'Tennessee',\n",
    "#     'TX': 'Texas',\n",
    "#     'UT': 'Utah',\n",
    "#     'VT': 'Vermont',\n",
    "#     'VA': 'Virginia',\n",
    "#     'WA': 'Washington',\n",
    "#     'WV': 'West Virginia',\n",
    "#     'WI': 'Wisconsin',\n",
    "#     'WY': 'Wyoming'\n",
    "# }\n",
    "\n",
    "# def seperate_locs(row):\n",
    "#     \"\"\"\n",
    "#     This was to verify that every location entry had matching state data.\n",
    "#     Long story short they did, so this is not actually needed.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         loc, state_abbrv = row['location'].split(', ')\n",
    "#     except Exception as e:\n",
    "#         print(row['location'])\n",
    "#         raise e\n",
    "#     row['abbrv'] = abbrv_map[state_abbrv]\n",
    "#     row['location'] = loc\n",
    "#     return row['location']\n",
    "# df['abbrv'] = df.apply(seperate_locs, axis=1)\n",
    "\n",
    "\n",
    "df['location'] = df['location'].str.replace('District of Columbia', 'District of Columbia, DC')\n",
    "df['location'] = df['location'].str.split(', ').apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "from feature_engine.discretisers import EqualWidthDiscretiser, EqualFrequencyDiscretiser\n",
    "import matplotlib.pyplot as plt\n",
    "df['checking_amt'] = df['checking_amt'].apply(float) # Stored as strings originally\n",
    "df.hist(column='checking_amt') # Display raw values\n",
    "\n",
    "\n",
    "# Binning is the way to go? Right now I have equal width.\n",
    "# Equal frequency maybe? But I don't think so with the distribution\n",
    "eqdist_discretiser = EqualWidthDiscretiser(\n",
    "    bins=10, \n",
    "    variables=['checking_amt']\n",
    ")\n",
    "df = eqdist_discretiser.fit_transform(df)\n",
    "\n",
    "df.hist(column='checking_amt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['savings'].apply(float).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none       516\n",
       "yes        357\n",
       "unknown    117\n",
       "Name: own_telephone, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['own_telephone'] = df['own_telephone'].mask(df['own_telephone'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['own_telephone'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['own_telephone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the ?s with other\n",
    "df['property_magnitude'] = df['property_magnitude'].mask(df['property_magnitude'] == \"?\", \"other\")\n",
    "# Remove the single quotes around the data\n",
    "df['property_magnitude'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "# Display the values as a sanity check\n",
    "df['property_magnitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "median = df[df['age'] != '?']['age'].apply(int).median()\n",
    "df['age'].mask(df['age'] == \"?\", median, inplace=True)\n",
    "df['age'] = df['age'].apply(int)\n",
    "df = df[df['age'].between(0, 100)]\n",
    "df.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing employment values with unknown\n",
    "df['employment'] = df['employment'].mask(df['employment'] == \"?\", \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "\n",
    "# Replacing missing personal_status values with unknown\n",
    "df['personal_status'] = df['personal_status'].mask(df['personal_status'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['personal_status'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['other_parties'] = df['other_parties'].mask(df['other_parties'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_parties'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the date to follow standard datetime format\n",
    "df['application_date']= pd.to_datetime(df['application_date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the credit_amount column without ?s\n",
    "no_miss_credit = df[df['credit_amount'] != \"?\"]\n",
    "# Convert to integer\n",
    "no_miss_credit = no_miss_credit.astype({\"credit_amount\": float})\n",
    "# Remove outliers and then calculate the average value\n",
    "mean = float(no_miss_credit['credit_amount'].mean())\n",
    "\n",
    "# Remove all ?s with the calculate average, also remove the outliers again\n",
    "df['credit_amount'] = df['credit_amount'].mask(df['credit_amount'] == \"?\", f\"{mean}\")\n",
    "df = df.astype({\"credit_amount\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing purpose values with unknown\n",
    "df['purpose'] = df['purpose'].mask(df['purpose'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['purpose'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from dateutil import parser\n",
    "# Convert to consistent format, set to use ordinal time so it is continious\n",
    "# Do we want that? Loses distinguishing info on month/year but makes continious\n",
    "s = df['application_date'].apply(lambda x: parser.parse(x).date().toordinal())\n",
    "\n",
    "# If we make continious we should also make normalize it.\n",
    "s = (s - s.min())/(s.max() - s.min())\n",
    "\n",
    "df['application_date'] = s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df[df['num_dependents'] != '?']['num_dependents'].apply(int).median()\n",
    "df['num_dependents'].mask(df['num_dependents'] == \"?\", median, inplace=True)\n",
    "df['num_dependents'] = df['num_dependents'].apply(int)\n",
    "df = df[df['num_dependents'].between(0, 5)]\n",
    "df.num_dependents.value_counts()\n",
    "\n",
    "# print(known_vals.mean()) # 2093625.787444934\n",
    "# known_vals = known_vals[known_vals >= 0]\n",
    "# known_vals = known_vals[known_vals <= 5] # The highest valid value seemed to be 2, but 5 just for good measure\n",
    "# # print(known_vals.mean()) # 1.1581858407079646\n",
    "# # print(df[known_vals.index].shape)\n",
    "# known_vals.median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job'].value_counts()\n",
    "# Replacing missing other_parties values with unknown\n",
    "df['job'].mask(df['job'] == \"?\", \"unknown\", inplace=True)\n",
    "# Remove the single quotes around the data\n",
    "df['job'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['job'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should NOT be run when we are finished\n",
    "# This naively removes all '?'s just to see some graphs quickly\n",
    "%matplotlib inline\n",
    "for col in numeric_cols:\n",
    "    df = df[df[col] != '?']\n",
    "    df[col] = df[col].apply(float)\n",
    "df.hist(figsize=(20,20))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df[numeric_cols], figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing credit_history values with unknown\n",
    "df['credit_history'] = df['credit_history'].mask(df['credit_history'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['credit_history'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['credit_history'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 7.154]      594\n",
       "(98.282, 9298.08]     99\n",
       "(7.154, 34.309]       99\n",
       "(65.862, 98.282]      99\n",
       "(34.309, 65.862]      99\n",
       "Name: savings, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Calculate the mean of savings and replace missing values with it\n",
    "mean = df[df['savings'] != '?']['savings'].apply(float).mean()\n",
    "df['savings'].mask(df['savings'] == \"?\", mean, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['savings'] = df['savings'].apply(float)\n",
    "# Bin by frequency\n",
    "df['savings'] = pd.qcut(df['savings'], q=10, duplicates='drop').astype(str) \n",
    "df['savings'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none       736\n",
       "bank       123\n",
       "unknown     87\n",
       "stores      44\n",
       "Name: other_payment_plans, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing other_payment_plans values with unknown\n",
    "df['other_payment_plans'] = df['other_payment_plans'].mask(df['other_payment_plans'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['other_payment_plans'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['other_payment_plans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "own         621\n",
       "rent        155\n",
       "unknown     114\n",
       "for free    100\n",
       "Name: housing, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['housing'] = df['housing'].mask(df['housing'] == \"?\", \"unknown\")\n",
    "# Remove the single quotes around the data\n",
    "df['housing'].replace(\"'(.*?)'\", \"\\\\1\", inplace=True, regex=True)\n",
    "df['housing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.000000    163\n",
       "24.000000    156\n",
       "18.000000    104\n",
       "20.807991     89\n",
       "36.000000     78\n",
       "6.000000      72\n",
       "15.000000     58\n",
       "9.000000      44\n",
       "48.000000     43\n",
       "30.000000     38\n",
       "21.000000     28\n",
       "10.000000     22\n",
       "27.000000     11\n",
       "60.000000     11\n",
       "42.000000      9\n",
       "11.000000      9\n",
       "20.000000      8\n",
       "8.000000       7\n",
       "4.000000       6\n",
       "45.000000      5\n",
       "7.000000       5\n",
       "39.000000      5\n",
       "28.000000      3\n",
       "14.000000      3\n",
       "22.000000      2\n",
       "54.000000      2\n",
       "33.000000      2\n",
       "13.000000      2\n",
       "40.000000      1\n",
       "16.000000      1\n",
       "5.000000       1\n",
       "26.000000      1\n",
       "72.000000      1\n",
       "Name: duration, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Calculate the mean of duration and replace missing values with it\n",
    "mean = df[df['duration'] != '?']['duration'].apply(float).mean()\n",
    "df['duration'].mask(df['duration'] == \"?\", mean, inplace=True)\n",
    "# Convert savings values to float\n",
    "df['duration'] = df['duration'].apply(float)\n",
    "df['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4    416\n",
       " 2    211\n",
       " 3    129\n",
       " 1    125\n",
       "-1    109\n",
       "Name: installment_commitment, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['installment_commitment'] = df['installment_commitment'].mask(df['installment_commitment'] == \"?\", \"-1\")\n",
    "df['installment_commitment'] = df['installment_commitment'].apply(int)\n",
    "df['installment_commitment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['residence_since'] = df['residence_since'].mask(df['residence_since'] == \"?\", \"-1\")\n",
    "df['residence_since'] = df['residence_since'].apply(int)\n",
    "df['residence_since'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In main script\n",
    "\"\"\"\n",
    "# Replacing missing housing values with unknown\n",
    "df['existing_credits'] = df['existing_credits'].mask(df['existing_credits'] == \"?\", \"-1\")\n",
    "df['existing_credits'] = df['existing_credits'].apply(int)\n",
    "df['existing_credits'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
